version: '3.8'

# 単一サーバー用設定ファイル - すべてのサービスを1台のマシンで実行
# 使用方法: docker-compose up -d

services:
  llm-api-backend:
    build:
      context: ./llm_eval_backend
      dockerfile: Dockerfile
    env_file:
      - ./.env  # ルート直下の統合された環境変数ファイルを使用
    ports:
      - "${API_PORT}:8000"
    volumes:
      - ./llm_eval_backend/src:/app/src
      - ./llm_eval_backend/results:/app/results
      - ./datasets:/external_datasets
      - ./external_data:/external_data
    environment:
      - LLMEVAL_ENV=${LLMEVAL_ENV}
      - LLMEVAL_LOG_LEVEL=${LLMEVAL_LOG_LEVEL}
      # MLflow接続設定
      - MLFLOW_TRACKING_URI=${MLFLOW_HOST_URI}
      - MLFLOW_HOST=${MLFLOW_HOST}
      - MLFLOW_PORT=${MLFLOW_PORT}
      # その他の設定
      - LLMEVAL_DB_PATH=${LLMEVAL_DB_PATH}
      - TZ=${TZ}
    depends_on:
      - llm-mlflow-tracking
      # 外部Ollamaサービスを使用するため、依存関係からollamaを削除
      # - llm-ollama-models
    hostname: llm-api-backend
    restart: unless-stopped
    networks:
      - llm-eval-network

  llm-mlflow-tracking:
    image: ghcr.io/mlflow/mlflow:latest
    ports:
      - "${MLFLOW_EXTERNAL_PORT}:5000"
    volumes:
      - ./llm_eval_backend/mlflow:/mlflow
    environment:
      - MLFLOW_TRACKING_URI=http://0.0.0.0:5000
      - MLFLOW_BACKEND_STORE_URI=sqlite:///mlflow/mlflow.db
      - MLFLOW_DEFAULT_ARTIFACT_ROOT=file:///mlflow/artifacts
      - MLFLOW_SERVE_ARTIFACTS=true
      - GUNICORN_CMD_ARGS="--access-logfile - --workers 1 --threads 2 --timeout 180 --forwarded-allow-ips='*' --log-level=debug"
      - ENABLE_CORS=true
      - MLFLOW_CORS_ALLOW_ALL_ORIGINS=true
      - MLFLOW_CORS_ALLOW_HEADERS=X-Requested-With,Content-Type,Authorization
      - MLFLOW_CORS_ALLOW_METHODS=GET,POST,PUT,DELETE,OPTIONS
    command: mlflow server --host 0.0.0.0 --backend-store-uri sqlite:///mlflow/mlflow.db --default-artifact-root file:///mlflow/artifacts --serve-artifacts --gunicorn-opts "--timeout 180 --log-level debug"
    user: root
    networks:
      - llm-eval-network
    restart: unless-stopped

  llm-frontend-app:
    build:
      context: ./llm_eval_frontend
      dockerfile: Dockerfile
    env_file:
      - ./.env  # ルート直下の統合された環境変数ファイルを使用
    ports:
      - "${FRONTEND_PORT}:3000"
    environment:
      # フロントエンド用環境変数
      - VITE_API_BASE_URL=${VITE_API_BASE_URL}
      - VITE_API_TIMEOUT=${VITE_API_TIMEOUT}
      - VITE_DEBUG_MODE=${VITE_DEBUG_MODE}
      - VITE_APP_NAME=${VITE_APP_NAME}
      - VITE_APP_VERSION=${VITE_APP_VERSION}
      - VITE_LOG_LEVEL=${VITE_LOG_LEVEL}
      # MLflow設定
      - MLFLOW_EXTERNAL_URI=http://${MLFLOW_EXTERNAL_HOST}:${MLFLOW_EXTERNAL_PORT}
      - VITE_MLFLOW_DIRECT_URL=${MLFLOW_EXTERNAL_URI}
      - MLFLOW_HOST=${MLFLOW_HOST}
      - MLFLOW_PORT=${MLFLOW_PORT}
      - VITE_MLFLOW_PROXY_ENDPOINT=${VITE_MLFLOW_PROXY_ENDPOINT}
      - VITE_MLFLOW_STATUS_ENDPOINT=${VITE_MLFLOW_STATUS_ENDPOINT}
      # 開発モード設定
      - VITE_DEV_SKIP_API_CHECK=${VITE_DEV_SKIP_API_CHECK:-false}
      - VITE_DEV_FORCE_MLFLOW_OK=${VITE_DEV_FORCE_MLFLOW_OK:-false}
    depends_on:
      - llm-api-backend
    networks:
      - llm-eval-network
    restart: always

networks:
  llm-eval-network:
    driver: bridge

volumes:
  mlflow: