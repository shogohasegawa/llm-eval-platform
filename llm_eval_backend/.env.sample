# アプリケーション設定
LLMEVAL_ENV=development
LLMEVAL_LOG_LEVEL=DEBUG

# データパス設定
LLMEVAL_DATASET_DIR=/external_datasets/test/
LLMEVAL_TRAIN_DIR=/external_datasets/n_shot/
LLMEVAL_RESULTS_DIR=./results

# モデル設定
# OpenAI
# Anthropic

# 共通設定
LLMEVAL_DEFAULT_MAX_TOKENS=1024
LLMEVAL_DEFAULT_TEMPERATURE=0.0
LLMEVAL_DEFAULT_TOP_P=1.0
LLMEVAL_MODEL_TIMEOUT=60.0

# 再試行設定
LLMEVAL_MODEL_RETRIES=3
LLMEVAL_RETRY_BACKOFF_MIN=2.0
LLMEVAL_RETRY_BACKOFF_MAX=30.0
LLMEVAL_RETRY_BACKOFF_MULTIPLIER=1.5

# キャッシュ設定
LLMEVAL_ENABLE_LITELLM_CACHE=false
LLMEVAL_CACHE_EXPIRATION=3600

# 処理設定
LLMEVAL_BATCH_SIZE=10
LLMEVAL_DEFAULT_NUM_SAMPLES=10
LLMEVAL_DEFAULT_N_SHOTS=[0, 2]

# プロバイダ設定
# LLMEVAL_ENABLED_PROVIDERS=["ollama", "openai", "anthropic"]

# MLflow設定
# コンテナ間通信用MLflowトラッキングURI
LLMEVAL_MLFLOW_TRACKING_URI=http://mlflow:5000
# 外部アクセス用MLflow URL（プロキシ用）
LLMEVAL_MLFLOW_EXTERNAL_URI=http://10.0.1.159:5000

# Ollama設定
# OllamaサーバーURL（分散デプロイメントの場合はGPUインスタンスのIPを指定）
LLMEVAL_OLLAMA_BASE_URL=http://10.0.1.159:11434
# OllamaのCORS設定
LLMEVAL_OLLAMA_ORIGINS=*
