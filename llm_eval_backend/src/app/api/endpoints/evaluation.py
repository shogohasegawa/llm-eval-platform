from fastapi import APIRouter, HTTPException, BackgroundTasks, Query, Path
from typing import Dict, Any, List, Optional, Union
import datetime
import time
import json
import traceback
import logging

from app.api.models import (
    EvaluationRequest, EvaluationResponse, MetricInfo, MetricsListResponse,
    AsyncEvaluationResponse, JobStatus, JobDetail, JobSummary, JobListResponse, JobLog, JobLogLevel
)
from app.core.evaluation import run_multiple_evaluations
from app.utils.logging import log_evaluation_results
from app.utils.litellm_helper import get_provider_options
from app.metrics import METRIC_REGISTRY
from app.utils.job_manager import get_job_manager

router = APIRouter(prefix="/evaluations", tags=["evaluations"])


@router.get("/metrics", response_model=MetricsListResponse)
async def get_available_metrics() -> MetricsListResponse:
    """
    åˆ©ç”¨å¯èƒ½ãªè©•ä¾¡æŒ‡æ¨™ä¸€è¦§ã‚’è¿”ã™

    Returns:
        MetricsListResponse: è©•ä¾¡æŒ‡æ¨™åã€èª¬æ˜ã€ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©ã®ãƒªã‚¹ãƒˆ
    """
    metrics_list: List[MetricInfo] = []
    
    # METRIC_REGISTRYã‹ã‚‰ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹è©•ä¾¡æŒ‡æ¨™ã‚’å–å¾—
    for name, metric_cls in METRIC_REGISTRY.items():
        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ä½œæˆã—ã¦æƒ…å ±ã‚’å–å¾—
        metric_instance = metric_cls()
        
        # docstringã‹ã‚‰èª¬æ˜ã‚’å–å¾—ï¼ˆå¯èƒ½ã§ã‚ã‚Œã°ï¼‰
        description = None
        if metric_cls.__doc__:
            description = metric_cls.__doc__.strip()
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©ã‚’å–å¾—
        param_defs = metric_cls.get_parameter_definitions()
        parameters = {}
        
        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿å®šç¾©ã‚’APIãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›
        for param_name, param_def in param_defs.items():
            parameters[param_name] = MetricParameterInfo(
                type=param_def.get("type", "string"),
                description=param_def.get("description"),
                default=param_def.get("default"),
                required=param_def.get("required", False),
                enum=param_def.get("enum")
            )
        
        metrics_list.append(
            MetricInfo(
                name=name,
                description=description,
                parameters=parameters if parameters else None,
                is_higher_better=getattr(metric_instance, "is_higher_better", True)
            )
        )
    
    # åå‰ã§ã‚½ãƒ¼ãƒˆ
    metrics_list.sort(key=lambda x: x.name)
    
    return MetricsListResponse(metrics=metrics_list)


@router.post("/run", response_model=Union[EvaluationResponse, AsyncEvaluationResponse])
async def evaluate(
    request: EvaluationRequest,
    background_tasks: BackgroundTasks
) -> Union[EvaluationResponse, AsyncEvaluationResponse]:
    """
    è¤‡æ•°ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã«å¯¾ã™ã‚‹LLMè©•ä¾¡ã‚’å®Ÿè¡Œã—ã€
    ä½¿ç”¨ã—ãŸãƒ¢ãƒ‡ãƒ«æƒ…å ±ã¨ãƒ•ãƒ©ãƒƒãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®ã¿ã‚’è¿”å´ã™ã‚‹ã‚·ãƒ³ãƒ—ãƒ«ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã€‚
    
    async_execution=Trueã®å ´åˆã¯ã€éåŒæœŸå®Ÿè¡Œã¨ãªã‚Šã€AsyncEvaluationResponseãŒè¿”å´ã•ã‚Œã‚‹ã€‚

    Args:
        request (EvaluationRequest): è©•ä¾¡å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€ãƒ¢ãƒ‡ãƒ«è¨­å®šã€ã‚µãƒ³ãƒ—ãƒ«æ•°ã€few-shotæ•°
        background_tasks (BackgroundTasks): ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ç™»éŒ²ç”¨

    Returns:
        Union[EvaluationResponse, AsyncEvaluationResponse]: 
            åŒæœŸå®Ÿè¡Œã®å ´åˆã¯ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã¨ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¾æ›¸ã€
            éåŒæœŸå®Ÿè¡Œã®å ´åˆã¯ã‚¸ãƒ§ãƒ–IDã¨ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹
    """
    # éåŒæœŸå®Ÿè¡Œã®å ´åˆ
    if request.async_execution:
        try:
            job_manager = get_job_manager()
            job = await job_manager.submit_job(request)
            
            return AsyncEvaluationResponse(
                job_id=job["id"],
                status=JobStatus(job["status"]),
                message="ã‚¸ãƒ§ãƒ–ãŒæ­£å¸¸ã«ã‚­ãƒ¥ãƒ¼ã«è¿½åŠ ã•ã‚Œã¾ã—ãŸ"
            )
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"éåŒæœŸã‚¸ãƒ§ãƒ–ã®ç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
    
    # åŒæœŸå®Ÿè¡Œã®å ´åˆï¼ˆæ—¢å­˜ã®å‡¦ç†ï¼‰
    try:
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‹ã‚‰ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã¨è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’å–å¾—
        provider_name = request.model.provider
        model_name = request.model.model_name
        
        # è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æº–å‚™ï¼ˆãƒ—ãƒ­ãƒã‚¤ãƒ€ã”ã¨ã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’é©ç”¨ï¼‰
        additional_params = get_provider_options(provider_name)
        
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼æŒ‡å®šã®è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’é©ç”¨ï¼ˆå„ªå…ˆï¼‰
        if request.model.additional_params:
            # ãƒ˜ãƒƒãƒ€ãƒ¼ã®å ´åˆã¯æ›´æ–°
            if "headers" in additional_params and "headers" in request.model.additional_params:
                additional_params["headers"].update(request.model.additional_params["headers"])
                # ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ãƒªã‚¯ã‚¨ã‚¹ãƒˆã®è¿½åŠ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰å‰Šé™¤ï¼ˆé‡è¤‡é©ç”¨ã‚’é¿ã‘ã‚‹ãŸã‚ï¼‰
                user_params = request.model.additional_params.copy()
                user_params.pop("headers", None)
                additional_params.update(user_params)
            else:
                # ãƒ˜ãƒƒãƒ€ãƒ¼ãŒãªã„å ´åˆã¯ãã®ã¾ã¾æ›´æ–°
                additional_params.update(request.model.additional_params)
        
        # 1) è©•ä¾¡ã‚¨ãƒ³ã‚¸ãƒ³å‘¼ã³å‡ºã—
        results_full: Dict[str, Any] = await run_multiple_evaluations(
            datasets=request.datasets,
            provider_name=provider_name,
            model_name=model_name,
            num_samples=request.num_samples,
            n_shots=request.n_shots,
            additional_params=additional_params
        )

        # 2) ãƒ•ãƒ©ãƒƒãƒˆãªãƒ¡ãƒˆãƒªã‚¯ã‚¹è¾æ›¸ã‚’ä½œæˆ - ã‚·ãƒ³ãƒ—ãƒ«ãªè§£æ±ºç­–
        flat_metrics: Dict[str, float] = {}
        for ds, ds_res in results_full.get("results", {}).items():
            details = ds_res.get("details", {})
            # ã‚¯ãƒªãƒ¼ãƒ³åŒ–ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆåã‚’å–å¾—
            clean_dataset_name = ds_res.get("metadata", {}).get("dataset", ds)
            logger.info(f"ğŸ“Š ãƒ•ãƒ©ãƒƒãƒˆãƒ¡ãƒˆãƒªã‚¯ã‚¹ä½œæˆ: dataset={ds}, clean_name={clean_dataset_name}")
            
            for key, value in details.items():
                # è©³ç´°çµæœã¨èª¤å·®ç‡ã¯é™¤å¤–
                if key.endswith("_details") or key.endswith("_error_rate") or key.endswith("_parameters"):
                    continue
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆå‰æ®µéšã§æ­£è¦åŒ–æ¸ˆã¿ï¼‰
                flat_metrics[key] = value

        # 3) ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§MLflowã¸ãƒ­ã‚°ï¼ˆãƒ‡ãƒãƒƒã‚°æœ‰åŠ¹åŒ–ï¼‰
        try:
            logger.info(f"ğŸ“Š ãƒªã‚¯ã‚¨ã‚¹ãƒˆå‡¦ç†å®Œäº†: MLflowã«ãƒ­ã‚®ãƒ³ã‚°ã‚’é–‹å§‹ã—ã¾ã™: {provider_name}/{model_name}")
            logger.info(f"ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®ä¾‹ (æœ€å¤§10ä»¶): {list(flat_metrics.items())[:10]}")
            
            # ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°ç”¨ï¼‰
            metrics_log_file = f"/app/debug_metrics_{provider_name}_{model_name}_{int(time.time())}.json"
            with open(metrics_log_file, "w") as f:
                json.dump({
                    "provider": provider_name,
                    "model": model_name,
                    "timestamp": datetime.datetime.now().isoformat(),
                    "metrics": flat_metrics
                }, f, indent=2)
            logger.info(f"ğŸ“Š ãƒ¡ãƒˆãƒªã‚¯ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ: {metrics_log_file}")
            
            # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯ã§ã¯ãªãç›´æ¥å®Ÿè¡Œã—ã¦ãƒ‡ãƒãƒƒã‚°ï¼ˆæœ¬ç•ªã§ã¯æˆ»ã™ï¼‰
            logging_result = await log_evaluation_results(
                model_name=f"{provider_name}/{model_name}",
                metrics=flat_metrics
            )
            logger.info(f"ğŸ“Š MLflowãƒ­ã‚®ãƒ³ã‚°çµæœ: {logging_result}")
            
            if not logging_result:
                logger.error(f"âŒ MLflowã¸ã®ãƒ­ã‚®ãƒ³ã‚°ãŒå¤±æ•—ã—ã¾ã—ãŸ: {provider_name}/{model_name}")
        except Exception as e:
            logger.error(f"âŒâŒâŒ MLflowãƒ­ã‚®ãƒ³ã‚°ä¸­ã«ä¾‹å¤–ãŒç™ºç”Ÿ: {str(e)}", exc_info=True)
            # ã‚¨ãƒ©ãƒ¼ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜éŒ²
            error_log_file = f"/app/mlflow_error_{provider_name}_{model_name}_{int(time.time())}.txt"
            with open(error_log_file, "w") as f:
                f.write(f"Error logging metrics for {provider_name}/{model_name}: {str(e)}\n\n")
                import traceback
                traceback.print_exc(file=f)
            logger.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã—ãŸ: {error_log_file}")
        
        # å…ƒã®ã‚³ãƒ¼ãƒ‰ï¼ˆç¾åœ¨ã¯éæ´»æ€§ï¼‰
        # background_tasks.add_task(
        #     log_evaluation_results,
        #     model_name=f"{provider_name}/{model_name}",
        #     metrics=flat_metrics
        # )

        # 4) ã‚·ãƒ³ãƒ—ãƒ«ãƒ¬ã‚¹ãƒãƒ³ã‚¹è¿”å´
        return EvaluationResponse(
            model_info=request.model,
            metrics=flat_metrics
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.get("/jobs", response_model=JobListResponse)
async def list_jobs(
    page: int = Query(1, ge=1, description="ãƒšãƒ¼ã‚¸ç•ªå·"),
    page_size: int = Query(10, ge=1, le=100, description="1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®ä»¶æ•°")
) -> JobListResponse:
    """
    è©•ä¾¡ã‚¸ãƒ§ãƒ–ã®ä¸€è¦§ã‚’å–å¾—
    
    Args:
        page: ãƒšãƒ¼ã‚¸ç•ªå·ï¼ˆ1ä»¥ä¸Šï¼‰
        page_size: 1ãƒšãƒ¼ã‚¸ã‚ãŸã‚Šã®ä»¶æ•°ï¼ˆ1ï½100ï¼‰
        
    Returns:
        JobListResponse: ã‚¸ãƒ§ãƒ–ä¸€è¦§ã¨ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³æƒ…å ±
    """
    try:
        job_manager = get_job_manager()
        result = job_manager.get_all_jobs(page, page_size)
        
        # APIãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›
        jobs = []
        for job in result["jobs"]:
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¿…è¦ãªæƒ…å ±ã‚’å–å¾—
            request_data = job["request_data"]
            if not request_data:
                continue
                
            model_info = request_data.get("model", {})
            
            # å¿…è¦ãªãƒ‡ãƒ¼ã‚¿ã®å¤‰æ›
            created_at = datetime.fromisoformat(job["created_at"]) if job["created_at"] else None
            updated_at = datetime.fromisoformat(job["updated_at"]) if job["updated_at"] else None
            completed_at = datetime.fromisoformat(job["completed_at"]) if job["completed_at"] else None
            
            jobs.append(JobSummary(
                id=job["id"],
                status=JobStatus(job["status"]),
                datasets=request_data.get("datasets", []),
                model_info=model_info,
                created_at=created_at,
                updated_at=updated_at,
                completed_at=completed_at
            ))
        
        return JobListResponse(
            jobs=jobs,
            total=result["total"],
            page=page,
            page_size=page_size
        )
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ã‚¸ãƒ§ãƒ–ä¸€è¦§ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")


@router.get("/jobs/{job_id}", response_model=JobDetail)
async def get_job(
    job_id: str = Path(..., description="ã‚¸ãƒ§ãƒ–ID")
) -> JobDetail:
    """
    ç‰¹å®šã®è©•ä¾¡ã‚¸ãƒ§ãƒ–ã®è©³ç´°ã‚’å–å¾—
    
    Args:
        job_id: ã‚¸ãƒ§ãƒ–ID
        
    Returns:
        JobDetail: ã‚¸ãƒ§ãƒ–ã®è©³ç´°æƒ…å ±
    """
    try:
        job_manager = get_job_manager()
        job = job_manager.get_job(job_id)
        
        if not job:
            raise HTTPException(status_code=404, detail=f"Job ID '{job_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # APIãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›
        created_at = datetime.fromisoformat(job["created_at"]) if job["created_at"] else None
        updated_at = datetime.fromisoformat(job["updated_at"]) if job["updated_at"] else None
        completed_at = datetime.fromisoformat(job["completed_at"]) if job["completed_at"] else None
        
        return JobDetail(
            id=job["id"],
            status=JobStatus(job["status"]),
            request=job["request_data"],
            result=job["result_data"],
            error_message=job["error_message"],
            created_at=created_at,
            updated_at=updated_at,
            completed_at=completed_at
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ã‚¸ãƒ§ãƒ–è©³ç´°ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")


@router.get("/jobs/{job_id}/logs", response_model=JobLog)
async def get_job_logs(
    job_id: str = Path(..., description="ã‚¸ãƒ§ãƒ–ID")
) -> JobLog:
    """
    ç‰¹å®šã®è©•ä¾¡ã‚¸ãƒ§ãƒ–ã®ãƒ­ã‚°ã‚’å–å¾—
    
    Args:
        job_id: ã‚¸ãƒ§ãƒ–ID
        
    Returns:
        JobLog: ã‚¸ãƒ§ãƒ–ã®ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®ãƒªã‚¹ãƒˆ
    """
    try:
        job_manager = get_job_manager()
        
        # ã‚¸ãƒ§ãƒ–ã®å­˜åœ¨ç¢ºèª
        job = job_manager.get_job(job_id)
        if not job:
            raise HTTPException(status_code=404, detail=f"Job ID '{job_id}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        
        # ãƒ­ã‚°ã®å–å¾—
        logs = job_manager.get_job_logs(job_id)
        
        # APIãƒ¢ãƒ‡ãƒ«ã«å¤‰æ›
        log_entries = []
        for log in logs:
            timestamp = datetime.fromisoformat(log["timestamp"]) if log["timestamp"] else None
            log_entries.append({
                "id": log["id"],
                "job_id": log["job_id"],
                "log_level": JobLogLevel(log["log_level"]),
                "message": log["message"],
                "timestamp": timestamp
            })
        
        return JobLog(
            logs=log_entries,
            job_id=job_id
        )
        
    except HTTPException:
        raise
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"ã‚¸ãƒ§ãƒ–ãƒ­ã‚°ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
