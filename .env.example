# LLM評価プラットフォーム統合環境変数設定ファイル
# ===========================================
# このファイルはシステム全体の環境変数を一元管理するためのテンプレートです
# このファイルをコピーして.envとして保存し、必要に応じて値を変更してください

#==============================
# 基本設定
#==============================
# 環境設定 (development, production)
# 用途: バックエンド動作モード設定、設定クラスで自動読み込み
LLMEVAL_ENV=production

# ログレベル (DEBUG, INFO, WARNING, ERROR)
# 用途: バックエンドログ設定、main.pyで読み込み
LLMEVAL_LOG_LEVEL=INFO

# データベースパス
# 用途: SQLiteデータベースの保存場所
LLMEVAL_DB_PATH=/external_data/llm_eval.db

# タイムゾーン設定
# 用途: コンテナ内のタイムゾーン設定
TZ=Asia/Tokyo

#==============================
# ネットワーク設定
#==============================
# APIサーバーポート (外部公開用)
# 用途: docker-compose.ymlでのポートマッピング
API_PORT=8001

# フロントエンドポート (外部公開用)
# 用途: docker-compose.ymlでのポートマッピング
FRONTEND_PORT=4173

# MLflowサーバー外部ポート
# 用途: docker-compose.ymlでのポートマッピング
MLFLOW_EXTERNAL_PORT=5000

#==============================
# MLflow設定
#==============================
# MLflowホスト名 (APIコンテナがMLflowに接続するホスト名)
# 用途: docker-compose.ymlでの接続、proxy.pyで使用
MLFLOW_HOST=mlflow

# MLflowポート (通常は変更不要)
# 用途: docker-compose.ymlでの接続、proxy.pyで使用
MLFLOW_PORT=5000

# MLflowホストURI (APIコンテナがMLflowに接続するURI)
# 用途: docker-compose.ymlでの接続、MLFLOW_TRACKING_URIにマップ
# proxy.pyでも使用
MLFLOW_HOST_URI=http://${MLFLOW_HOST}:${MLFLOW_PORT}

# 外部アクセス用MLflow URL設定
# 用途: ブラウザや外部システムからのアクセス用
# 開発環境ではlocalhost、本番環境では実際のサーバーIPを設定
MLFLOW_EXTERNAL_HOST=localhost
# MLflowコンテナを外部公開するポート番号
# docker-compose.ymlのポートマッピングに合わせる必要あり ("5001:5000")
MLFLOW_EXTERNAL_PORT=5001
# 外部アクセス用の完全なURI（プロキシや直接アクセスで共通利用）
# バックエンドとフロントエンドの両方で使用される共通設定
MLFLOW_EXTERNAL_URI=http://${MLFLOW_EXTERNAL_HOST}:${MLFLOW_EXTERNAL_PORT}

#==============================
# フロントエンド設定
#==============================
# APIサーバーのURL
# 用途: フロントエンドからAPIへの接続設定
# 空白の場合は相対パスを使用（プロキシ経由で接続）
VITE_API_BASE_URL=

# フロントエンド用MLflow設定
# 用途: フロントエンドからMLflowへの接続設定
# ブラウザから直接アクセスするためのURL
VITE_MLFLOW_DIRECT_URL=${MLFLOW_EXTERNAL_URI}
# API経由でのMLflowへのプロキシパス
VITE_MLFLOW_PROXY_ENDPOINT=/proxy-mlflow
# MLflow状態確認用のエンドポイント
VITE_MLFLOW_STATUS_ENDPOINT=/mlflow-status
# MLflowの設定（バックエンド設定をフロントエンドでも使用するため共有）
# これらはbackendのMLFLOW_HOSTとMLFLOW_PORTを使用することを推奨
MLFLOW_HOST=llm-mlflow-tracking
MLFLOW_PORT=5000

# フロントエンド用Ollama設定
# APIリクエストのタイムアウト設定（ミリ秒）
# 用途: API呼び出しの最大待機時間
VITE_API_TIMEOUT=60000

# デバッグモード（開発環境では true に設定）
# 用途: 詳細なログ出力とデバッグ情報の表示
VITE_DEBUG_MODE=true

# 開発モード特別設定
# 用途: 開発環境での動作設定
# API接続チェックをスキップするかどうか
VITE_DEV_SKIP_API_CHECK=false
# MLflow接続を常に成功とみなすかどうか
VITE_DEV_FORCE_MLFLOW_OK=false

# アプリケーション名
# 用途: UI表示用のアプリケーション名
VITE_APP_NAME=LLM評価プラットフォーム

# アプリケーションバージョン
# 用途: UI表示用のバージョン情報
VITE_APP_VERSION=1.0.0

# ログレベル（DEBUG, INFO, WARN, ERROR）
# 用途: フロントエンドのログ出力レベル設定
VITE_LOG_LEVEL=INFO

#==============================
# オプション設定
#==============================
# CORS設定 (カンマ区切りで複数指定可)
# 用途: バックエンドのCORS設定
# 本番環境では特定のドメインに限定することを推奨
CORS_ORIGINS=*